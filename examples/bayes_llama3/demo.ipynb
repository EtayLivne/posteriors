{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "\n",
    "def load_ensemble(filepaths):\n",
    "    def load_from_checkpoint(idx, filepath):\n",
    "        parameters = torch.load(filepath)['state_dict']['bayesian_layer'].params\n",
    "        parameters = {re.sub(r'model\\.layers\\.\\d+\\.', '', k): v for k, v in parameters.items() if v.numel() > 0}\n",
    "        return parameters\n",
    "    return [load_from_checkpoint(idx, filepath) for idx, filepath in enumerate(filepaths)]\n",
    "\n",
    "parameters = load_ensemble(['logs/bayes/checkpoints/epoch=0-step=300.ckpt','logs/bayes/checkpoints/epoch=9-step=3000.ckpt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'self_attn.q_proj.weight': tensor([[ 8.3618e-03, -3.4790e-03,  7.8735e-03,  ..., -1.0548e-03,\n",
       "           -1.6842e-03, -1.7662e-03],\n",
       "          [ 3.4180e-03, -1.7166e-03,  1.3428e-02,  ..., -1.5991e-02,\n",
       "           -3.9062e-03,  1.0443e-03],\n",
       "          [ 7.3395e-03,  1.2207e-02, -1.0376e-02,  ...,  8.3745e-05,\n",
       "           -2.6733e-02,  3.2501e-03],\n",
       "          ...,\n",
       "          [-6.5498e-03,  1.6846e-02,  1.4221e-02,  ..., -1.0132e-02,\n",
       "           -1.6602e-02,  2.4048e-02],\n",
       "          [-1.7944e-02, -2.4902e-02,  1.0803e-02,  ..., -3.4424e-02,\n",
       "            2.3766e-03, -2.2217e-02],\n",
       "          [-3.6640e-03, -1.7090e-02,  1.1414e-02,  ...,  2.1152e-03,\n",
       "           -5.5552e-04, -5.3406e-04]], device='cuda:0', dtype=torch.float16,\n",
       "         requires_grad=True),\n",
       "  'self_attn.k_proj.weight': tensor([[ 0.0126, -0.0272,  0.0303,  ...,  0.0481, -0.0056,  0.0067],\n",
       "          [-0.0266, -0.0155, -0.0435,  ..., -0.0216, -0.0515,  0.0091],\n",
       "          [ 0.0107,  0.0065,  0.0159,  ..., -0.0048, -0.0022, -0.0027],\n",
       "          ...,\n",
       "          [-0.0197,  0.0422, -0.0142,  ..., -0.0164, -0.0437,  0.0079],\n",
       "          [ 0.0312,  0.0232,  0.0240,  ..., -0.0170, -0.0284, -0.0432],\n",
       "          [-0.0092,  0.0048,  0.0143,  ..., -0.0170, -0.0391,  0.0198]],\n",
       "         device='cuda:0', dtype=torch.float16, requires_grad=True),\n",
       "  'self_attn.v_proj.weight': tensor([[ 0.0171,  0.0178, -0.0025,  ..., -0.0255, -0.0188,  0.0130],\n",
       "          [-0.0052,  0.0041, -0.0131,  ..., -0.0074,  0.0082, -0.0030],\n",
       "          [-0.0427, -0.0253, -0.0144,  ..., -0.0292,  0.0300, -0.0129],\n",
       "          ...,\n",
       "          [ 0.0078,  0.0007, -0.0005,  ...,  0.0096, -0.0043, -0.0043],\n",
       "          [-0.0015, -0.0041, -0.0073,  ..., -0.0107, -0.0013, -0.0214],\n",
       "          [-0.0231,  0.0023,  0.0057,  ...,  0.0069, -0.0096, -0.0069]],\n",
       "         device='cuda:0', dtype=torch.float16, requires_grad=True),\n",
       "  'self_attn.o_proj.weight': tensor([[ 1.9897e-02, -1.2756e-02, -2.2339e-02,  ...,  1.1841e-02,\n",
       "           -2.7122e-03,  1.3428e-02],\n",
       "          [ 2.8467e-04, -3.4943e-03, -4.3640e-03,  ...,  1.3580e-03,\n",
       "            4.4799e-04,  1.0498e-02],\n",
       "          [-7.3242e-03,  1.2939e-02, -8.2397e-03,  ..., -5.7745e-04,\n",
       "            7.3242e-03, -6.0730e-03],\n",
       "          ...,\n",
       "          [ 1.5411e-03,  1.1002e-02, -4.4861e-03,  ..., -7.3528e-04,\n",
       "           -1.0233e-03,  1.2695e-02],\n",
       "          [-1.6724e-02,  3.0823e-03,  1.6724e-02,  ..., -2.1172e-04,\n",
       "           -1.1902e-02,  7.2937e-03],\n",
       "          [ 1.7944e-02, -2.0905e-03,  1.5991e-02,  ..., -1.9775e-02,\n",
       "            9.0942e-03, -9.4473e-05]], device='cuda:0', dtype=torch.float16,\n",
       "         requires_grad=True),\n",
       "  'mlp.gate_proj.weight': tensor([[-1.4160e-02,  1.5503e-02, -2.3071e-02,  ...,  1.3855e-02,\n",
       "            4.3640e-03,  6.9847e-03],\n",
       "          [-7.6675e-04,  7.7209e-03,  7.5912e-03,  ...,  1.5381e-02,\n",
       "            7.3547e-03,  1.2207e-02],\n",
       "          [-1.1169e-02,  2.0264e-02, -1.4099e-02,  ...,  6.4697e-03,\n",
       "           -7.1411e-03, -5.6505e-05],\n",
       "          ...,\n",
       "          [ 5.4016e-03, -3.8452e-03,  2.5879e-02,  ...,  2.7161e-03,\n",
       "            1.7700e-02,  1.7700e-02],\n",
       "          [-1.7822e-02, -1.7822e-02,  5.0964e-03,  ...,  1.3245e-02,\n",
       "           -8.7280e-03, -1.1108e-02],\n",
       "          [-2.7222e-02, -2.6855e-02, -2.3560e-02,  ...,  3.6865e-02,\n",
       "            3.9062e-02,  8.4839e-03]], device='cuda:0', dtype=torch.float16,\n",
       "         requires_grad=True),\n",
       "  'mlp.up_proj.weight': tensor([[-0.0166, -0.0251, -0.0056,  ...,  0.0182, -0.0078,  0.0094],\n",
       "          [ 0.0062,  0.0013,  0.0124,  ...,  0.0077,  0.0342, -0.0030],\n",
       "          [ 0.0052,  0.0024,  0.0063,  ..., -0.0089,  0.0143, -0.0221],\n",
       "          ...,\n",
       "          [ 0.0262,  0.0019,  0.0187,  ...,  0.0049,  0.0111,  0.0003],\n",
       "          [-0.0051,  0.0134, -0.0087,  ...,  0.0062,  0.0013,  0.0118],\n",
       "          [ 0.0096, -0.0139, -0.0018,  ..., -0.0046, -0.0034, -0.0092]],\n",
       "         device='cuda:0', dtype=torch.float16, requires_grad=True),\n",
       "  'mlp.down_proj.weight': tensor([[-0.0344,  0.0157,  0.0188,  ...,  0.0021,  0.0121,  0.0008],\n",
       "          [-0.0042, -0.0064,  0.0030,  ..., -0.0031,  0.0032, -0.0089],\n",
       "          [-0.0090, -0.0223, -0.0219,  ...,  0.0034, -0.0059, -0.0084],\n",
       "          ...,\n",
       "          [ 0.0126,  0.0019, -0.0045,  ..., -0.0164, -0.0075,  0.0112],\n",
       "          [-0.0132,  0.0069,  0.0142,  ..., -0.0195,  0.0114,  0.0111],\n",
       "          [-0.0074, -0.0138,  0.0107,  ...,  0.0106,  0.0027,  0.0031]],\n",
       "         device='cuda:0', dtype=torch.float16, requires_grad=True),\n",
       "  'input_layernorm.weight': tensor([0.4648, 0.4004, 0.4453,  ..., 0.4297, 0.3906, 0.3008], device='cuda:0',\n",
       "         dtype=torch.float16, requires_grad=True),\n",
       "  'post_attention_layernorm.weight': tensor([0.5273, 0.4902, 0.5078,  ..., 0.5273, 0.4883, 0.4258], device='cuda:0',\n",
       "         dtype=torch.float16, requires_grad=True)},\n",
       " {'self_attn.q_proj.weight': tensor([[ 0.0084, -0.0091,  0.0061,  ..., -0.0164, -0.0024,  0.0035],\n",
       "          [ 0.0259, -0.0060,  0.0156,  ..., -0.0160, -0.0196, -0.0050],\n",
       "          [-0.0009,  0.0013, -0.0104,  ...,  0.0046, -0.0267, -0.0022],\n",
       "          ...,\n",
       "          [-0.0080,  0.0168,  0.0144,  ..., -0.0101, -0.0166,  0.0240],\n",
       "          [-0.0179, -0.0249, -0.0036,  ..., -0.0344, -0.0042, -0.0222],\n",
       "          [-0.0003, -0.0171, -0.0047,  ..., -0.0106,  0.0051, -0.0006]],\n",
       "         device='cuda:0', dtype=torch.float16, requires_grad=True),\n",
       "  'self_attn.k_proj.weight': tensor([[-0.0040, -0.0272,  0.0303,  ...,  0.0481,  0.0157,  0.0146],\n",
       "          [-0.0266, -0.0073, -0.0435,  ..., -0.0216, -0.0515, -0.0017],\n",
       "          [ 0.0116,  0.0054,  0.0068,  ...,  0.0001,  0.0037, -0.0137],\n",
       "          ...,\n",
       "          [-0.0197,  0.0422, -0.0156,  ..., -0.0164, -0.0437,  0.0058],\n",
       "          [ 0.0312,  0.0232,  0.0240,  ..., -0.0170, -0.0284, -0.0432],\n",
       "          [-0.0092,  0.0024,  0.0156,  ..., -0.0151, -0.0391,  0.0173]],\n",
       "         device='cuda:0', dtype=torch.float16, requires_grad=True),\n",
       "  'self_attn.v_proj.weight': tensor([[ 1.7090e-02,  1.7822e-02, -6.6643e-03,  ..., -2.5513e-02,\n",
       "           -1.8799e-02,  1.9226e-02],\n",
       "          [ 2.8954e-03, -8.3625e-05, -1.5625e-02,  ..., -1.0841e-02,\n",
       "            8.2397e-03, -7.8125e-03],\n",
       "          [-4.2725e-02, -2.5269e-02, -1.4404e-02,  ..., -2.9175e-02,\n",
       "            3.0029e-02, -1.2878e-02],\n",
       "          ...,\n",
       "          [ 1.0246e-02,  7.8125e-03,  1.4618e-02,  ...,  9.6436e-03,\n",
       "            3.1052e-03, -2.6398e-03],\n",
       "          [-5.3253e-03, -1.9646e-03, -5.4169e-03,  ..., -1.3474e-02,\n",
       "           -6.0005e-03, -2.1729e-02],\n",
       "          [-2.3071e-02,  1.4969e-02,  7.8125e-03,  ...,  1.2268e-02,\n",
       "           -1.4366e-02, -8.8654e-03]], device='cuda:0', dtype=torch.float16,\n",
       "         requires_grad=True),\n",
       "  'self_attn.o_proj.weight': tensor([[ 1.9897e-02, -1.2726e-02, -2.2339e-02,  ...,  1.1635e-02,\n",
       "            7.7744e-03,  1.2993e-02],\n",
       "          [ 3.1776e-03, -6.3705e-03, -3.5858e-03,  ...,  6.3972e-03,\n",
       "            1.2466e-02,  1.0498e-02],\n",
       "          [ 3.9101e-03,  6.3286e-03, -2.9221e-03,  ..., -4.4727e-04,\n",
       "            6.9199e-03, -1.9264e-03],\n",
       "          ...,\n",
       "          [ 3.3894e-03,  1.0864e-02, -1.4816e-02,  ..., -3.5019e-03,\n",
       "            2.7885e-03,  1.2695e-02],\n",
       "          [-1.6724e-02,  6.6662e-04,  1.6724e-02,  ...,  2.7409e-03,\n",
       "           -1.1902e-02,  4.5929e-03],\n",
       "          [ 1.7944e-02,  2.1100e-05,  1.5991e-02,  ..., -1.9775e-02,\n",
       "            8.5144e-03,  4.7951e-03]], device='cuda:0', dtype=torch.float16,\n",
       "         requires_grad=True),\n",
       "  'mlp.gate_proj.weight': tensor([[-0.0144, -0.0035, -0.0231,  ...,  0.0146, -0.0116,  0.0148],\n",
       "          [ 0.0118,  0.0222, -0.0021,  ...,  0.0156,  0.0105,  0.0122],\n",
       "          [-0.0112,  0.0203, -0.0156,  ...,  0.0078,  0.0019, -0.0012],\n",
       "          ...,\n",
       "          [ 0.0108,  0.0017,  0.0259,  ..., -0.0010,  0.0177,  0.0177],\n",
       "          [-0.0091, -0.0178,  0.0056,  ...,  0.0156, -0.0015, -0.0111],\n",
       "          [-0.0272, -0.0269, -0.0236,  ...,  0.0369,  0.0391,  0.0053]],\n",
       "         device='cuda:0', dtype=torch.float16, requires_grad=True),\n",
       "  'mlp.up_proj.weight': tensor([[-0.0166, -0.0251, -0.0044,  ...,  0.0275, -0.0067,  0.0094],\n",
       "          [-0.0057, -0.0080,  0.0201,  ...,  0.0075,  0.0342, -0.0016],\n",
       "          [ 0.0084,  0.0142,  0.0010,  ..., -0.0089,  0.0141, -0.0221],\n",
       "          ...,\n",
       "          [ 0.0262,  0.0028,  0.0207,  ...,  0.0010,  0.0122,  0.0078],\n",
       "          [-0.0020,  0.0134, -0.0052,  ...,  0.0032,  0.0055,  0.0118],\n",
       "          [ 0.0096, -0.0109,  0.0074,  ...,  0.0003, -0.0156, -0.0156]],\n",
       "         device='cuda:0', dtype=torch.float16, requires_grad=True),\n",
       "  'mlp.down_proj.weight': tensor([[-0.0344,  0.0157,  0.0188,  ...,  0.0048,  0.0104, -0.0005],\n",
       "          [ 0.0015, -0.0020, -0.0015,  ..., -0.0145,  0.0007, -0.0089],\n",
       "          [-0.0086, -0.0197, -0.0219,  ...,  0.0156, -0.0058, -0.0042],\n",
       "          ...,\n",
       "          [ 0.0164,  0.0003, -0.0120,  ..., -0.0164, -0.0119,  0.0109],\n",
       "          [-0.0199,  0.0077,  0.0156,  ..., -0.0195,  0.0156,  0.0111],\n",
       "          [-0.0121, -0.0110,  0.0053,  ...,  0.0118, -0.0008, -0.0015]],\n",
       "         device='cuda:0', dtype=torch.float16, requires_grad=True),\n",
       "  'input_layernorm.weight': tensor([0.4648, 0.4004, 0.4453,  ..., 0.4297, 0.3906, 0.3008], device='cuda:0',\n",
       "         dtype=torch.float16, requires_grad=True),\n",
       "  'post_attention_layernorm.weight': tensor([0.5273, 0.4902, 0.5078,  ..., 0.5273, 0.4883, 0.4258], device='cuda:0',\n",
       "         dtype=torch.float16, requires_grad=True)}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/miniconda/envs/posteriors/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.10it/s]\n",
      "Some weights of BayesLlamaForCausalLM were not initialized from the model checkpoint at Meta-Llama-3-8B and are newly initialized: ['model.bayesian_layers.0.input_layernorm.weight', 'model.bayesian_layers.0.mlp.down_proj.weight', 'model.bayesian_layers.0.mlp.gate_proj.weight', 'model.bayesian_layers.0.mlp.up_proj.weight', 'model.bayesian_layers.0.post_attention_layernorm.weight', 'model.bayesian_layers.0.self_attn.k_proj.weight', 'model.bayesian_layers.0.self_attn.o_proj.weight', 'model.bayesian_layers.0.self_attn.q_proj.weight', 'model.bayesian_layers.0.self_attn.v_proj.weight', 'model.bayesian_layers.1.input_layernorm.weight', 'model.bayesian_layers.1.mlp.down_proj.weight', 'model.bayesian_layers.1.mlp.gate_proj.weight', 'model.bayesian_layers.1.mlp.up_proj.weight', 'model.bayesian_layers.1.post_attention_layernorm.weight', 'model.bayesian_layers.1.self_attn.k_proj.weight', 'model.bayesian_layers.1.self_attn.o_proj.weight', 'model.bayesian_layers.1.self_attn.q_proj.weight', 'model.bayesian_layers.1.self_attn.v_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from llama3.modules.bayesllama_copy import BayesLlamaForCausalLM\n",
    "\n",
    "bayes = BayesLlamaForCausalLM.from_pretrained(\"Meta-Llama-3-8B\").to(\"cuda\")\n",
    "bayes.load_bayesian_layers(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Meta-Llama-3-8B\")\n",
    "\n",
    "inputs = \"This is a test\"\n",
    "inputs = tokenizer(inputs, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bayes(inputs.to(\"cuda\"), return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
